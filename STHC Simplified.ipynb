{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Citation information:\n",
    "\n",
    "David S. Lamb 2017 \"Identifying Nodes of Transmission in Disease Diffusion Through Social Media\" Doctoral Dissertation University of South Florida\n",
    "\n",
    "http://scholarcommons.usf.edu/etd/6883/\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check For 64-bit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'64bit'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import platform\n",
    "platform.architecture()[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Libraries\n",
    "\n",
    "### Arcpy license"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import arcpy\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "from igraph import *\n",
    "#import arcpy\n",
    "import math\n",
    "from rtree import index\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import csv\n",
    "import matplotlib as mpl\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from scipy.spatial.distance import pdist, squareform\n",
    "from scipy.cluster.hierarchy import dendrogram\n",
    "from scipy.cluster.hierarchy import linkage\n",
    "from scipy.cluster.hierarchy import fcluster\n",
    "from sklearn.metrics import silhouette_samples, silhouette_score\n",
    "from datetime import timedelta\n",
    "import datetime\n",
    "import pytz\n",
    "import fiona\n",
    "from shapely.geometry import LineString, Point, shape, mapping\n",
    "from dateutil import parser\n",
    "from fiona.crs import from_epsg\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "from sklearn import metrics\n",
    "from scipy import spatial\n",
    "from scipy.sparse import coo_matrix\n",
    "from scipy.sparse import csgraph\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Develop graph from input points for calculating network distances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class graphFromLinesAndPoints(object):\n",
    "    \n",
    "    def __init__(self,indexAndPoints):\n",
    "        self.nodeIDPoints =indexAndPoints\n",
    "        self.G = None#Graph()#nx.Graph()\n",
    "        self.K  = 10\n",
    "        self.epsilon = .001\n",
    "        self.allNodesMatch = {}\n",
    "        self.allNodesMatchWithLines = {}\n",
    "        self.rtIndex = None\n",
    "        #self.totalNetworkDistance=0\n",
    "        self.weights = []\n",
    "        self.nodesTemporary = []\n",
    "        self.edgesTemporary = []\n",
    "        self.pntIndexToNodeID = {}\n",
    "        self.NodeIDtopntIndex = {}\n",
    "        self.pntLst = []\n",
    "        self.lowerDM = None\n",
    "        self.baseforsparse = []\n",
    "        self.pntMat = None\n",
    "    def distance(self,x1,y1,x2,y2):\n",
    "        dx = x1-x2\n",
    "        dy = y1-y2\n",
    "        return math.sqrt(dx*dx+dy*dy)\n",
    "    \n",
    "    def distanceNode(self,node1,node2):\n",
    "        dx = node1[0]-node2[0]\n",
    "        dy = node1[1]-node2[1]\n",
    "        return math.sqrt(dx*dx+dy*dy)\n",
    "    \n",
    "    #need to contend with duplicate points...\n",
    "    def developGraphFromTriangulation(self):\n",
    "        #self.edgesTemporary = []\n",
    "        self.pntLst = range(0,len(self.nodeIDPoints.keys()))\n",
    "        self.pntIndexToNodeID = {}\n",
    "        self.NodeIDtopntIndex = {}\n",
    "        print \"Remove Duplicates\"\n",
    "        for i,k in enumerate(self.nodeIDPoints.keys()):\n",
    "            self.pntLst[i] = self.nodeIDPoints[k]\n",
    "            \n",
    "        \n",
    "            \n",
    "        XC = np.array(self.pntLst)\n",
    "        self.pointMat = XC\n",
    "        print \"creating triangulation\"\n",
    "        tri = spatial.Delaunay(XC)\n",
    "        data_l = []\n",
    "        col_l = []\n",
    "        row_l = []\n",
    "        existingPairs = []\n",
    "        ids = []\n",
    "        for t in tri.simplices:\n",
    "            \n",
    "            ds = spatial.distance.pdist(np.vstack([XC[t[0]],XC[t[1]],XC[t[2]]]),'euclidean')\n",
    "            ids.extend(t)\n",
    "            self.weights.append(ds[0])\n",
    "            self.weights.append(ds[1])\n",
    "            self.weights.append(ds[2])\n",
    "            pair = (t[0],t[1])\n",
    "            if not pair in existingPairs:\n",
    "                row_l.append(t[0])\n",
    "                col_l.append(t[1])\n",
    "                data_l.append(ds[0])\n",
    "                existingPairs.append(pair)\n",
    "            pair = (t[0],t[2])\n",
    "            if not pair in existingPairs:\n",
    "                row_l.append(t[0])\n",
    "                col_l.append(t[2])\n",
    "                data_l.append(ds[1])\n",
    "                existingPairs.append(pair)\n",
    "            pair = (t[1],t[2])\n",
    "            if not pair in existingPairs:\n",
    "                row_l.append(t[1])\n",
    "                col_l.append(t[2])\n",
    "                data_l.append(ds[2])\n",
    "                existingPairs.append(pair)\n",
    "        self.baseforsparse = zip(row_l,col_l,data_l)\n",
    "        \n",
    "\n",
    "        print \"creating spatial index from unique points\"\n",
    "        triids = list(set(ids))\n",
    "        self.rtIndex = spatial.KDTree(XC[triids])\n",
    "        print \"match points to their index\"\n",
    "        for i,k in enumerate(self.nodeIDPoints.keys()):\n",
    "            pnt = np.array(self.nodeIDPoints[k])\n",
    "            trq = self.rtIndex.query(pnt,k=1)\n",
    "            closestID = triids[trq[1]]\n",
    "            self.pntIndexToNodeID[closestID]=k\n",
    "            self.NodeIDtopntIndex[k]=closestID\n",
    "\n",
    "        print \"Sparse Matrix\"\n",
    "        self.G = coo_matrix((np.array(data_l),(np.array(row_l),np.array(col_l))),shape=(len(XC),len(XC)))\n",
    "        print \"Lower Distance Matrix\"\n",
    "        #self.lowerDM = np.tril(csgraph.shortest_path(self.G,directed=False))\n",
    "        self.lowerDM = np.tril(csgraph.dijkstra(self.G,directed=False))                     \n",
    "\n",
    "        ##self.G.add_nodes_from(self.nodeIDPoints.keys())\n",
    "        #print \"creating graph\"\n",
    "        #for t in tri.simplices:\n",
    "            #k1= self.pntLstNodeCheck[t[0]]\n",
    "            #k2=self.pntLstNodeCheck[t[1]]\n",
    "            #k3=self.pntLstNodeCheck[t[2]]\n",
    "            #node1 = self.nodeIDPoints[k1]\n",
    "            #node2 = self.nodeIDPoints[k2]\n",
    "            #node3 = self.nodeIDPoints[k3]\n",
    "            #self.edgesTemporary.append([k1,k2,self.distanceNode(node1,node2)])\n",
    "            #self.edgesTemporary.append([k1,k2,self.distanceNode(node1,node2)])\n",
    "            #self.weights.append(self.distanceNode(node1,node2))\n",
    "            #self.edgesTemporary.append([k1,k3,self.distanceNode(node1,node3)])\n",
    "            #self.edgesTemporary.append([k1,k3])\n",
    "            #self.weights.append(self.distanceNode(node1,node3))\n",
    "            #self.edgesTemporary.append([k2,k3,self.distanceNode(node2,node3)])\n",
    "            #self.edgesTemporary.append([k2,k3])\n",
    "            # self.weights.append(self.distanceNode(node2,node3))\n",
    "            \n",
    "        #self.G.add_weighted_edges_from(self.edgesTemporary,weight='distance')\n",
    "        #self.G.add_vertices(self.nodeIDPoints.keys())\n",
    "        #self.G.add_edges(self.edgesTemporary)\n",
    "        #self.G.es[\"distance\"] = self.weights\n",
    "\n",
    "        #if len(self.pntLst) <=1000:\n",
    "            #nx.draw(self.G,pos=self.nodeIDPoints)\n",
    "            #layout = self.G.layout(\"fr\")\n",
    "            #plot(self.G, layout = layout)\n",
    "        \n",
    "\n",
    "\n",
    "    \n",
    "    #def buildGraphDistanceMatrix(self,K):\n",
    "        #get the nearest neighbors list\n",
    "        #print \"find cutoff\"\n",
    "        #dist,nkn = self.rtIndex.query(self.pntLst,K*2)\n",
    "        #print \"create dm\"\n",
    "        #nodeIndex = {v.index:v['name']}\n",
    "        #self.distanceIndexNodeID = {v['name']:v.index}\n",
    "    \n",
    "        #for i in self.pntLstNodeCheck.keys():\n",
    "            #maxDist = max(dist[i])\n",
    "            #sourceNode = self.pntLstNodeCheck[i]\n",
    "            #self.sparseDistanceMatrixNodeID[sourceNode] = nx.single_source_dijkstra_path_length(self.G,sourceNode,weight='distance',cutoff=maxDist)\n",
    "        #print \"looking vertices\"\n",
    "        #for v in self.G.vs:\n",
    "            #nodeID = v['name']\n",
    "            #nodeDM = self.G.shortest_paths()\n",
    "            #if self.numpyDistanceMatrix == None:\n",
    "                #self.numpyDistanceMatrix = np.array(nodeDM[0])\n",
    "            #else:\n",
    "                #self.numpyDistanceMatrix=np.vstack([self.numpyDistanceMatrix,nodeDM[0]])\n",
    "            #del nodeDM\n",
    "    def getNodeDistances(self,nodeID1,nodeID2):\n",
    "        ind1 = self.NodeIDtopntIndex[nodeID1]\n",
    "        ind2 = self.NodeIDtopntIndex[nodeID2]\n",
    "        if ind1 > ind2:\n",
    "            dist = self.lowerDM[ind1][ind2]\n",
    "        else:\n",
    "            dist = self.lowerDM[ind2][ind1]\n",
    "        if dist == 0 or dist<0 or dist==np.Inf:\n",
    "            return None\n",
    "        else:\n",
    "            return dist\n",
    "    \n",
    "        return None\n",
    "    \n",
    "    \n",
    "    def getMaxKNearest(self,nodeID,K):\n",
    "        #try:\n",
    "        #stuff = []\n",
    "        #keys = set(self.p.keys())\n",
    "        i = self.NodeIDtopntIndex[nodeID]\n",
    "        #print \"in node id %s\"%nodeID\n",
    "        #print \"pnt index %s\"%i\n",
    "        #stuff = []\n",
    "        #for j in self.pntIndexToNodeID.keys():\n",
    "            #if j!=i:\n",
    "                #if i > j:\n",
    "                    #dist = self.lowerDM[i][j]\n",
    "                #else:\n",
    "                    #dist = self.lowerDM[j][i]\n",
    "                #if dist != 0 or dist!=np.Inf:\n",
    "                    #stuff.append(dist)\n",
    "        stuff = [x for x in self.lowerDM[i+1:,i] if x != np.inf]+[x for x in self.lowerDM[i,0:i] if x != np.inf]\n",
    "        #print stuff\n",
    "        stuff = sorted(stuff)\n",
    "        #stuff = sorted([x for x in self.lowerDM[i+1:,i]])#[self.p[nodeID][k] for k in self.p[nodeID].keys() if k in keys and k!=nodeID]\n",
    "        #sorts = sorted(stuff)\n",
    "        if max(stuff[0:K]) == 0:\n",
    "            return 1.0\n",
    "\n",
    "        return max(stuff[0:K])\n",
    "       #except Exception as e:\n",
    "        #    print \"error\"\n",
    "        #    print nodeID\n",
    "        #    print str(e)\n",
    "        #    return 1.0\n",
    "    \n",
    "    def getMaxKNearDict(self,keys, K):\n",
    "        maxLst = {}\n",
    "        for n in keys:\n",
    "            maxLst[n] = self.getMaxKNearest(n,K)\n",
    "        return maxLst\n",
    "                               \n",
    "            \n",
    "            \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hierarchical clustering using linear weighted combination of Space Time and Attribute values\n",
    "\n",
    "## Based on distance matrix approach in Scipy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class st_hierarchical_net(object):\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.K = 10\n",
    "        self.pointFeatureClass = \"\"#path to pointFeature Class\n",
    "        self.gdbPath = \"\"\n",
    "        self.outputPathFC = \"\"\n",
    "        self.outputNameFC = \"\"\n",
    "        self.timeScale = 86400 #used in the coversion to a nonlinear function\n",
    "        self.timeByScale = 3600 #Scale data to this value\n",
    "        self.timeCenter = 43200\n",
    "        self.attribScale = 1\n",
    "        self.idxTreeNodeID = {}\n",
    "        self.timeField = \"\"\n",
    "        self.attribField = \"\"\n",
    "        self.indexPointID = {}\n",
    "        self.maxKNearest = {}\n",
    "        self.df = None #pandas data frame\n",
    "        self.dm = None #sparse distance matrix\n",
    "        self.dfdm = None #pandas data frame of distance matrix\n",
    "        self.row_clusters = None\n",
    "        self.local_time_zone = None\n",
    "        self.weights = []\n",
    "        self.useridfield = None\n",
    "        self.indexidfield = None\n",
    "        self.indexuseridmatch = {}\n",
    "        self.labels = []\n",
    "        \n",
    "    def loadDataset(self):\n",
    "        \n",
    "\n",
    "        variables = ['NodeID', 'Time','Attribute']\n",
    "        self.labels = []\n",
    "        x_lst = []\n",
    "        idx = 0\n",
    "        nodeIds = {}\n",
    "        \n",
    "        #with arcpy.da.SearchCursor(self.pointFeatureClass,[\"SHAPE@XY\",\"SHAPE@\",self.timeField,self.attribField,\"OID@\",self.useridfield]) as sc:\n",
    "        with fiona.open(self.gdbPath,'r',layer=self.pointFeatureClass) as coll:\n",
    "            i = 1\n",
    "            for row in coll:\n",
    "                s = shape(row['geometry'])\n",
    "                indexValue = None\n",
    "                if self.indexidfield:\n",
    "                    self.labels.append(row['properties'][self.indexidfield])\n",
    "                    indexValue = row['properties'][self.indexidfield]\n",
    "                else:\n",
    "                    self.labels.append(i)\n",
    "                    indexValue = i\n",
    "                    i+=1\n",
    "                    \n",
    "                nodeIds[indexValue]={}\n",
    "                dt = row['properties'][self.timeField]\n",
    "                x_lst.append([int(indexValue),dt,row['properties'][self.attribField]])\n",
    "                \n",
    "                self.indexPointID[indexValue] = (s.coords[0][0],s.coords[0][1])\n",
    "                if self.useridfield:\n",
    "                    self.indexuseridmatch[indexValue] = row['properties'][self.useridfield]\n",
    "                #idx+=1\n",
    "        self.internalGraph = graphFromLinesAndPoints(self.indexPointID)\n",
    "        self.internalGraph.developGraphFromTriangulation()\n",
    "        self.totalNetworkLength = sum(self.internalGraph.weights)\n",
    "        \n",
    "        X = np.array(x_lst)\n",
    "        self.df = pd.DataFrame(X, columns=variables, index=self.labels)\n",
    "        self.df['NodeID'] = self.df['NodeID'].astype(int)\n",
    "        #print \"length dictionary\"\n",
    "        #self.internalGraph.buildGraphDistanceMatrix(self.K)\n",
    "        #self.p = self.internalGraph.sparseDistanceMatrixNodeID\n",
    "        print \"get max k\"\n",
    "        self.maxKNearest = self.internalGraph.getMaxKNearDict(self.internalGraph.NodeIDtopntIndex.keys(),self.K)\n",
    "        #for key in self.p.keys():\n",
    "            #self.maxKNearest[key]=self.getMaxKNearest(key)\n",
    "        \n",
    "        print \"Creating distance matrix\"\n",
    "        print X\n",
    "        self.dm = pdist(X, self.calcDistanceMetric)\n",
    "        #self.sqdm = squareform(self.dm)\n",
    "        print \"create clusters\"\n",
    "        self.row_clusters = linkage(self.dm,method='average')\n",
    "        plt.title('Hierarchical Clustering Dendrogram')\n",
    "        plt.xlabel('Index')\n",
    "        plt.ylabel('Distance')\n",
    "        #row_dendr = dendrogram(self.row_clusters,labels=self.labels)\n",
    "\n",
    "        \n",
    "    \n",
    "        \n",
    "    def calcDistanceMetric(self,x,y):\n",
    "        #assumed that there are three dimensions\n",
    "        #dist = self.internalGraph.findShortestPathLength(arcpy.Point(x[0],x[1]),arcpy.Point(y[0],y[1])) #\n",
    "        \n",
    "        nearestMax = self.maxKNearest[int(x[0])]\n",
    "\n",
    "        #dists = self.p[int(x[0])]\n",
    "        dist = self.internalGraph.getNodeDistances(int(x[0]),int(y[0]))\n",
    "        if dist == None:\n",
    "            dist = self.totalNetworkLength /2.0\n",
    "        \n",
    "        #dist = dists[y[0]]\n",
    "        #print dist\n",
    "        distSc = float(dist) / nearestMax#(float(self.totalNetworkLength)/2.0)\n",
    "        #print distSc\n",
    "        t1 = x[1] - self.timeCenter #centered to noon, assuming seconds from midnight\n",
    "        t2 = y[1] - self.timeCenter #centered to noon, assuming seconds from midnight\n",
    "        \n",
    "        a1 = x[2]\n",
    "        a2 = y[2]\n",
    "        \n",
    "        \n",
    "        if self.weights[0]*x[0] == self.weights[0]*y[0] and self.weights[1]*t1==self.weights[1]*t2 and self.weights[2]*a1==self.weights[2]*a2:\n",
    "            #print \"equals\"\n",
    "            return 0.0\n",
    "\n",
    "        \n",
    "        tSec = abs(t1 - t2) \n",
    "        tRad = math.pi * (float(tSec)/self.timeScale) #convert time to radians, half unit circle\n",
    "        #https://en.wikipedia.org/wiki/Law_of_cosines\n",
    "        #https://stats.stackexchange.com/questions/36152/converting-similarity-matrix-to-euclidean-distance-matrix\n",
    "        #convert =  math.pi * (float(self.timeByScale)/self.timeScale)\n",
    "        #dtSin = float((math.sin(dtSc)))/convert\n",
    "        tCos = math.cos(tRad)\n",
    "        tDist = math.sqrt((t1*t1+t2*t2)-(2*t1*t2*tCos))#law of cosines to convert it to euclidean space\n",
    "        da = np.abs(x[2]-y[2])\n",
    "        daSc = da / self.attribScale\n",
    "        dtSc = float(tDist)/self.timeByScale #scaled to a value if in seconds 3600 is seconds from midnight\n",
    "        res = float(self.weights[0]*distSc + self.weights[1]*dtSc+ self.weights[2]*daSc)/(sum(self.weights))\n",
    "        #res = math.sqrt(distSc*distSc + dtSc*dtSc + daSc*daSc)\n",
    "        if res >=0.0:\n",
    "            return res\n",
    "        else:\n",
    "            return 0.0\n",
    "    \n",
    "    def datetime_to_float(self,d):\n",
    "        epoch_utc = pytz.utc\n",
    "        epoch = datetime.datetime.utcfromtimestamp(0)\n",
    "        epochdt = epoch_utc.localize(epoch,is_dst=None)\n",
    "        total_seconds =  (d - epochdt).total_seconds()\n",
    "        # total_seconds will be in decimals (millisecond precision)\n",
    "        return total_seconds\n",
    "\n",
    "    def float_to_datetime(self,fl):\n",
    "        return datetime.datetime.utcfromtimestamp(fl)\n",
    "    \n",
    "    def silohetteScore(self,n_clusters,printV=False):\n",
    "        outScores = []\n",
    "        sqdm = squareform(self.dm)\n",
    "        for n_c in n_clusters:\n",
    "            try:\n",
    "                #print \"number of clusters %s\"%n_c\n",
    "                cluster_labels = fcluster(self.row_clusters, n_c, criterion='maxclust')\n",
    "                #print cluster_labels\n",
    "                silhouette_avg = silhouette_score(sqdm,cluster_labels,metric='precomputed')\n",
    "                #silhouette_avg = silhouette_score(self.sqdm + self.sqdm.T,cluster_labels,metric='euclidean')\n",
    "                outScores.append(silhouette_avg)\n",
    "                if printV:\n",
    "                    print \"For n_clusters =%s\"%n_c\n",
    "                    print \"The average silhouette_score is : %s\"%silhouette_avg\n",
    "            except:\n",
    "                pass\n",
    "        del sqdm\n",
    "        return outScores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "sth = st_hierarchical_net()\n",
    "sth.K = 7\n",
    "sth.pointFeatureClass = \"jimmy_2_6\"#\"comparisonDataset_20\"#\"allgeo_validsources_utm_random_la_sm\"# \"allgeo_validsources_utm_noident\"#path to pointFeature Class\n",
    "sth.gdbPath = r\"C:\\Users\\David\\OneDrive\\projects\\STHC\\dataset.gdb\"#r\"C:\\Users\\David\\OneDrive\\projects\\SNN-Net\\simWorking\\sim_db.gdb\"#r\"C:\\Users\\David\\OneDrive\\projects\\dissertationWork\\data\\allGeoTaggedMessages.gdb\"#r\"C:\\Users\\David\\OneDrive\\projects\\dissertationWork\\data\\allGeoTaggedMessages.gdb\"\n",
    "sth.outputPathFC = \"\"\n",
    "sth.outputNameFC = \"\"\n",
    "sth.timeScale = 86400\n",
    "sth.timeByScale = 3600#t #standard deviation may provide a good way to set this\n",
    "sth.attribScale = 1\n",
    "sth.timeField = \"TOTSEC\"#\"time\"#\"secfrmmid\" #assumed to be string since shapefiles cannot handle datetimes\n",
    "sth.attribField =\"ATTR\"#\"ATTRIB\"#\"attrib\"\n",
    "sth.weights=[.2,1.0,0.0]\n",
    "#sth.useridfield = \"ATTR\"\n",
    "#sth.indexidfield = \"Try\"\n",
    "print \"process data\"\n",
    "sth.loadDataset()\n",
    "#tracker[t][k]['sth'] = sth+\n",
    "#tracker[t][k]['scores']= sth.silohetteScore(cs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
